{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.060842Z",
     "start_time": "2019-05-14T23:57:20.053165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 3381982\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = unidecode(open('./sherlock.txt').read())\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.077596Z",
     "start_time": "2019-05-14T23:57:20.064808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 256  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to one-hot tensor.\n",
    "def seq_to_onehot(seq):\n",
    "    tensor = torch.zeros(len(seq), 1, n_chars) \n",
    "    # Shape of the tensor:\n",
    "    #     (sequence length, batch size, classes)\n",
    "    # Here we use batch size = 1 and classes = number of unique characters.\n",
    "    for t, char in enumerate(seq):\n",
    "        index = all_chars.index(char)\n",
    "        tensor[t][0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), 1)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_onehot(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]).long() # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.437344Z",
     "start_time": "2019-05-14T23:57:20.131573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (rnn): RNNCell(100, 150)\n",
       "  (linear): Linear(in_features=150, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Initialization.\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size  = n_chars   # Input size: Number of unique chars.\n",
    "        self.hidden_size = 150       # Hidden size: 100.\n",
    "        self.output_size = n_chars   # Output size: Number of unique chars.\n",
    "        \n",
    "        self.rnn = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\" Forward function.\n",
    "              input:  One-hot input. It refers to the x_t in homework write-up.\n",
    "              hidden: Previous hidden state. It refers to the h_{t-1}.\n",
    "            Returns (output, hidden) where output refers to y_t and \n",
    "                     hidden refers to h_t.\n",
    "        \"\"\"\n",
    "        # Forward function.\n",
    "        hidden = self.rnn(input, hidden)\n",
    "        output = self.linear(hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initial hidden state.\n",
    "        # 1 means batch size = 1.\n",
    "        return torch.zeros(1, self.hidden_size).to(device) \n",
    "    \n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Step and Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.449539Z",
     "start_time": "2019-05-14T23:57:22.440333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training step function.\n",
    "def train_step(net, opt, input, target):\n",
    "    \"\"\" Training step.\n",
    "        net:    The network instance.\n",
    "        opt:    The optimizer instance.\n",
    "        input:  Input tensor.  Shape: [seq_len, 1, n_chars].\n",
    "        target: Target tensor. Shape: [seq_len, 1].\n",
    "    \"\"\"\n",
    "    seq_len = input.shape[0]    # Get the sequence length of current input.\n",
    "    hidden = net.init_hidden()  # Initial hidden state.\n",
    "    net.zero_grad()             # Clear the gradient.\n",
    "    loss = 0                    # Initial loss.\n",
    "\n",
    "    for t in range(seq_len):    # For each one in the input sequence.\n",
    "        output, hidden = net(input[t], hidden)\n",
    "        loss += loss_func(output, target[t])\n",
    "\n",
    "    loss.backward()             # Backward. \n",
    "    opt.step()                  # Update the weights.\n",
    "\n",
    "    return loss / seq_len       # Return the average loss w.r.t sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:36.378318Z",
     "start_time": "2019-05-15T03:10:36.366394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation step function.\n",
    "def eval_step(net, init_seq='W', predicted_len=100):\n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden        = net.init_hidden()\n",
    "    init_input    = seq_to_onehot(init_seq).to(device)\n",
    "    predicted_seq = init_seq\n",
    "\n",
    "    # Use initial string to \"build up\" hidden state.\n",
    "    for t in range(len(init_seq) - 1):\n",
    "        output, hidden = net(init_input[t], hidden)\n",
    "        \n",
    "    # Set current input as the last character of the initial string.\n",
    "    input = init_input[-1]\n",
    "    \n",
    "    # Predict more characters after the initial string.\n",
    "    for t in range(predicted_len):\n",
    "        # Get the current output and hidden state.\n",
    "        output, hidden = net(input, hidden)\n",
    "        \n",
    "        # Sample from the output as a multinomial distribution.\n",
    "        predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "        \n",
    "        # Add predicted character to the sequence and use it as next input.\n",
    "        predicted_char  = all_chars[predicted_index]\n",
    "        predicted_seq  += predicted_char\n",
    "        \n",
    "        # Use the predicted character to generate the input of next round.\n",
    "        input = seq_to_onehot(predicted_char)[0].to(device)\n",
    "\n",
    "    return predicted_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.556497Z",
     "start_time": "2019-05-14T23:57:22.478732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:99/20000 loss:3.078964288234711\n",
      "generated sequence: W(ietp  arer nWtii..ohtt  .nuchc? dyvrah tIwerctwi\n",
      "oas rrt i ah    amteec .d tem oseotot  nkn o hNhen\n",
      "\n",
      "iter:199/20000 loss:2.7963463115692138\n",
      "generated sequence: Wiyo narghulces u aon wicushbosilnga.tohe hhtl  tyocrf fmunuls .irryocecittee a-fhe   ylnarwe t  hhet\n",
      "\n",
      "iter:299/20000 loss:2.4918797612190247\n",
      "generated sequence: Wce?\n",
      "\n",
      "    y ued wotile Isouwerotd-Thenile mimen'lant thap.ant somattet fmad, ame mopu!jaly . ?ust\"rhe\n",
      "\n",
      "iter:399/20000 loss:2.3214094638824463\n",
      "generated sequence: W-\"whee drerkighvepiwhlre aocpes angatd the ced waplo tho  h cho koutwin wost nt aug metwan!lcweokn N\n",
      "\n",
      "iter:499/20000 loss:2.221277060508728\n",
      "generated sequence: Wax)qtics ind Abqmerall, tomenk eor cee, Saln.\n",
      "\n",
      "      \"remamwengrede ftomeny Domenk s'ont we clenle. \n",
      "\n",
      "iter:599/20000 loss:2.237410236597061\n",
      "generated sequence: W\n",
      " T   Acksacotseningod, awas ot af thicho, B\n",
      "     ?\"AA you michiws\n",
      "\n",
      "     fery er hey wurkeind su ine\n",
      "\n",
      "iter:699/20000 loss:2.115425571203232\n",
      "generated sequence: Wege ofer ined poultutiithel shive wave, Lhat  Hankt\n",
      "     \"Ges ropinl tish con, boncerGy. way of icha\n",
      "\n",
      "iter:799/20000 loss:2.0992861866950987\n",
      "generated sequence: Weuc,  no dyou shouckstongluedy derouk, ow ih argeve; Sole chas\n",
      "     tlly to had larued ger I me oig\n",
      "\n",
      "\n",
      "iter:899/20000 loss:2.0030160081386565\n",
      "generated sequence: Wed qustmprmod yoo hould and eprestely th! steror Hond\n",
      "     Guncin yourt,\n",
      "     Wawidcadt shen! On/om \n",
      "\n",
      "iter:999/20000 loss:1.9954853785037994\n",
      "generated sequence: Whi freeecy some; heare thad buen, and you dos\n",
      "     leAed, thI dreald wapr chuict on ir wis dwisk,\" t\n",
      "\n",
      "iter:1099/20000 loss:1.9725520944595336\n",
      "generated sequence: Whtingtes yous do bifneverionstamesorevan var. Ihes in grerasingwcod thind hestont cama ditd you,,\n",
      "  \n",
      "\n",
      "iter:1199/20000 loss:1.9550348019599915\n",
      "generated sequence: Welt tejrise paidey. Hndount and\n",
      "     be thin thenbe was leld thenper ha for douf ht with ong of\n",
      "    \n",
      "\n",
      "iter:1299/20000 loss:1.955392255783081\n",
      "generated sequence: Wat he\n",
      "     matreerol w or coratlowe in Bash ye  EaJk aw sis luted thes, ap pas crastall, th to the h\n",
      "\n",
      "iter:1399/20000 loss:1.8796530640125275\n",
      "generated sequence: We uly asced pome whohe you\n",
      "\n",
      "     hild, wathe the hives droicid beansed nel kivide angoflaingleatible\n",
      "\n",
      "iter:1499/20000 loss:1.887821031808853\n",
      "generated sequence: With\n",
      "     ully, yot I heapare.\"\n",
      "\n",
      "     He. I dssereriok, be the canet in\n",
      "     tever.\n",
      "     me ame wo hi\n",
      "\n",
      "iter:1599/20000 loss:1.8702658534049987\n",
      "generated sequence: We vooken syereat senerverte nowing me. \"Yeliting, muss ghat ih Himetothy wish se cagnther bat'\n",
      "     \n",
      "\n",
      "iter:1699/20000 loss:1.8515469741821289\n",
      "generated sequence: We hadse bedor hall. The seewhes leve,\n",
      "     have?\"\n",
      "\n",
      "     Where des cessele chus  We sintcall the ver \n",
      "\n",
      "iter:1799/20000 loss:1.8603046834468842\n",
      "generated sequence: We wourd have reatenabusebrt. The ham. I's, a min the Emerving lagess abent-ast borms.\" hin\n",
      "\n",
      "     \" h\n",
      "\n",
      "iter:1899/20000 loss:1.8462026596069336\n",
      "generated sequence: Whay bul of all had sy. Ho nom uwon somery and man brourvar now hor thathiry, war his w's a mame cal \n",
      "\n",
      "iter:1999/20000 loss:1.8091344678401946\n",
      "generated sequence: Whes, andenger, Ind\n",
      "    'sed jopurmaid will will in or lanersighte pooning un was nenubiblay somminon\n",
      "\n",
      "iter:2099/20000 loss:1.8267243635654449\n",
      "generated sequence: We aroull\n",
      "     a soare. I ell ctanch of -werigoot of a apo me?t at't urouroll was instsert.\"\n",
      "\n",
      "     \"H\n",
      "\n",
      "iter:2199/20000 loss:1.8144267833232879\n",
      "generated sequence: Wellid!\"\n",
      "\n",
      "     \"Marding andithe wrile, there pagning of wathermad your\", feof with he ruf with as he \n",
      "\n",
      "iter:2299/20000 loss:1.7823416483402252\n",
      "generated sequence: Whing ancerisstounce. Ofly\n",
      "     veiy to had herlertuplay thet gat?\"\n",
      "\n",
      "     \"Whan?\"\n",
      "\n",
      "     \"That y cacks\n",
      "\n",
      "iter:2399/20000 loss:1.7850983870029449\n",
      "generated sequence: Wags and\n",
      "     ceang\n",
      "     mose me!\" He way thet ane.\"\n",
      "\n",
      "     \"How you nen anleansion all the wiol, in t\n",
      "\n",
      "iter:2499/20000 loss:1.7574964272975921\n",
      "generated sequence: Wencatle wave oun sint aaror found,\" shis Bramponed hul radnkly bo\n",
      "     oit. I wird ond blow, ccate t\n",
      "\n",
      "iter:2599/20000 loss:1.7568213737010956\n",
      "generated sequence: Welforn; you caileds and proasiling he at the\n",
      "     and had on y\n",
      "     y tried of the matie of with a l\n",
      "\n",
      "iter:2699/20000 loss:1.7723573017120362\n",
      "generated sequence: We sangaid nevere of tonoughras to allibgethman so us-atrestiod his proimes at an my\n",
      "     faobmey and\n",
      "\n",
      "iter:2799/20000 loss:1.7323623871803284\n",
      "generated sequence: Willer, Wavaly wited betading he hay a sonves is ind whither hed we his menterict\n",
      "     my tore and is\n",
      "\n",
      "iter:2899/20000 loss:1.7577825939655305\n",
      "generated sequence: Wasmrwammer the sand\n",
      "     a pospe nal you.\"\n",
      "\n",
      "     He out fir. Holdon\n",
      "     cof. I\n",
      "     con who  andey \n",
      "\n",
      "iter:2999/20000 loss:1.748552099466324\n",
      "generated sequence: We.\n",
      "     Fres ubon, then th mught sig th org alr hxarving teres dentome,, foull gottant attef chathed\n",
      "\n",
      "iter:3099/20000 loss:1.742321650981903\n",
      "generated sequence: We lotr, and Anfort it was a fose queger by hered\n",
      "     it inteer. We rafpes in a custed my fift read \n",
      "\n",
      "iter:3199/20000 loss:1.7308697557449342\n",
      "generated sequence: We maded to bely, turted, slower cand fiving, be ince thus! It whocked the what wast with me of the b\n",
      "\n",
      "iter:3299/20000 loss:1.723291299343109\n",
      "generated sequence: Wetance: carred coll ward the begow, and the exparenteveg to horn have alforettion; mis wothing his v\n",
      "\n",
      "iter:3399/20000 loss:1.7105254030227661\n",
      "generated sequence: Whis. \"Yo  \" the uppovad his noous\n",
      "      thet brandly am the hidfer alayous, and thore?\"\n",
      "\n",
      "     \"'Whe \n",
      "\n",
      "iter:3499/20000 loss:1.6891524195671082\n",
      "generated sequence: We\n",
      "     dow got!\"\n",
      "\n",
      "     \"Anof of the mymared Luppoulie ibsingigaling horess. You of your daruing the \n",
      "\n",
      "iter:3599/20000 loss:1.697623028755188\n",
      "generated sequence: With a shorleme. We cas clockndy a prothen le\n",
      "     retter of fing ous very his a thathe ment to sick \n",
      "\n",
      "iter:3699/20000 loss:1.6616107666492461\n",
      "generated sequence: Welter-wardw that aloomen's man podstort at a freind fentere, sagasly stordshist hall alve,\n",
      "     prov\n",
      "\n",
      "iter:3799/20000 loss:1.691246633529663\n",
      "generated sequence: Watsout of tiredole mosher in she tay the ray ane am old hering indies, I am Ird inture we her\n",
      "     M\n",
      "\n",
      "iter:3899/20000 loss:1.6707556879520415\n",
      "generated sequence: We the poctery of I thenures the tear that'I nairingonily for the ilar and a compurten that last bich\n",
      "\n",
      "iter:3999/20000 loss:1.675615783929825\n",
      "generated sequence: We\n",
      "     I\n",
      "     doon, I let It he mas, and tear of I sand ha, were surton there is byong remesposting \n",
      "\n",
      "iter:4099/20000 loss:1.6613579297065735\n",
      "generated sequence: Wh\n",
      "     capeed sive the pansigne tibe a heather. I has carsicheccreat a stine.\"\n",
      "\n",
      "     \"I have as a sh\n",
      "\n",
      "iter:4199/20000 loss:1.671790738105774\n",
      "generated sequence: Wans, and so is in inag homevil your an\n",
      "     in't hemectane, and dly go druck homevered you sard is t\n",
      "\n",
      "iter:4299/20000 loss:1.672966375350952\n",
      "generated sequence: Wely devered his the hould a folker, and he will man no when net con?\"\n",
      "\n",
      "     \"Welked you his\n",
      "     pon\n",
      "\n",
      "iter:4399/20000 loss:1.6927571392059326\n",
      "generated sequence: Wands, andsent your sent, and no have lay. when by the bloned, and to morgons where have tolve, as is\n",
      "\n",
      "iter:4499/20000 loss:1.6623632109165192\n",
      "generated sequence: We\n",
      "     frous shell aty thansow, had the Kinm. It ounyers as our ccier. Gure. Gavon the baps.\n",
      "     Fe\n",
      "\n",
      "iter:4599/20000 loss:1.6444220507144929\n",
      "generated sequence: What the ans of the wentianoveruschal, ans-beck. Aut of priend hontor. 'neasoned. Therryor, bect came\n",
      "\n",
      "iter:4699/20000 loss:1.651861845254898\n",
      "generated sequence: Wels, buch as he madu!\" Haldle neshags, Mr. Had.\"\n",
      "\n",
      "     \"Yes, not, for posely\n",
      "\n",
      "    m-Hoppen morn poin\n",
      "\n",
      "iter:4799/20000 loss:1.6394120013713838\n",
      "generated sequence: Whin; be sovethers insther.\n",
      "     You\n",
      "     ast, would me so dos  oun glak a\n",
      "     tent a tore which it \n",
      "\n",
      "iter:4899/20000 loss:1.6222996866703034\n",
      "generated sequence: What thisk in Frigh how eneslang confiden,\n",
      "     us seng it in giors been saken that the greary\n",
      "     c\n",
      "\n",
      "iter:4999/20000 loss:1.6192500007152557\n",
      "generated sequence: We save a can Enght you aves you will an ard to upon\n",
      "     we-ap that is it instablued Holmes my nave \n",
      "\n",
      "iter:5099/20000 loss:1.6491413581371308\n",
      "generated sequence: We and I have ame him.\n",
      "     I give a pus there.\"\n",
      "\n",
      "      ut in Pirant. He weithe wot ot have not, lown\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:5199/20000 loss:1.618125925064087\n",
      "generated sequence: Well, en casceused is a have you receec, him. I offace, fourteivind the coning the ather in my owanin\n",
      "\n",
      "iter:5299/20000 loss:1.649488558769226\n",
      "generated sequence: Wit who I mest had\n",
      "     they litt yinay dagger go. He seikhown what staression. It wall! As insomithe\n",
      "\n",
      "iter:5399/20000 loss:1.6213734173774719\n",
      "generated sequence: Was and\n",
      "     rerooble still ham\n",
      "     dirzinted. \"Why matwe from you suct\n",
      "     fruadled time that\n",
      "    \n",
      "\n",
      "iter:5499/20000 loss:1.6095736992359162\n",
      "generated sequence: Watins to fe and lape.\"\n",
      "\n",
      "     \"No?\"\n",
      "\n",
      "     \"The\n",
      "     molker.\"\n",
      "\n",
      "     \"Now, of EItrige. OA relemed of th\n",
      "\n",
      "iter:5599/20000 loss:1.6355764806270598\n",
      "generated sequence: We lisely biguraswore before a ficht is more. Of a mandery bs ope your from no hew \"'Top companisard \n",
      "\n",
      "iter:5699/20000 loss:1.6223457908630372\n",
      "generated sequence: We strangerdessat to Ehumprie, some makever.\"\n",
      "\n",
      "     \"Whetention to when was\n",
      "     gral whother it. Qum\n",
      "\n",
      "iter:5799/20000 loss:1.6271488440036774\n",
      "generated sequence: Waslatily le vase, but the waple and a himat once untoocouser that they which me to hell surent out t\n",
      "\n",
      "iter:5899/20000 loss:1.6165067434310914\n",
      "generated sequence: Whal anit the lin sofe, to the tolleman fear motticuust fource here when I wols iw ofe repleted untel\n",
      "\n",
      "iter:5999/20000 loss:1.5869132363796234\n",
      "generated sequence: Wayson to dight to fan it, and a keef conly and thin seckets of\n",
      "     miken ouricion for over it my do\n",
      "\n",
      "iter:6099/20000 loss:1.6120806515216828\n",
      "generated sequence: Whichtunch down dangly.\n",
      "\n",
      "     The whank for wos ding arable waytenfed with not be adombok, for the ca\n",
      "\n",
      "iter:6199/20000 loss:1.5927668380737305\n",
      "generated sequence: We world he inturoat befo met at his edesiared\n",
      "     me not himsel take a\n",
      "     restle\n",
      "     holve sharm\n",
      "\n",
      "iter:6299/20000 loss:1.5911207139492034\n",
      "generated sequence: Wr met matell of looklestly afteir like that which the late of thrinds for mellutely was face the ver\n",
      "\n",
      "iter:6399/20000 loss:1.5938242840766907\n",
      "generated sequence: We the sidn down\n",
      "     no shougnt my sand over to meed by owh the blang his\n",
      "     have be more not gone\n",
      "\n",
      "iter:6499/20000 loss:1.5904522407054902\n",
      "generated sequence: Wef aw it the selits. \"Do! I revelt\n",
      "     nowe.\n",
      "\n",
      "     \"Sow onough my anainming reate it may houses eve\n",
      "\n",
      "iter:6599/20000 loss:1.566408601999283\n",
      "generated sequence: Whiss, Mis coke pectinech I just.\"\n",
      "\n",
      "     \"Inderstoves, young of up tonny them, we subord minding, his\n",
      "\n",
      "iter:6699/20000 loss:1.57234623670578\n",
      "generated sequence: With, and I fough wrorertoon of the raundedon my young might be oflier his sowh and hip weras and see\n",
      "\n",
      "iter:6799/20000 loss:1.5992144095897673\n",
      "generated sequence: Where the there my he very stake in and af-Screatan\n",
      "     polmman only intaguliting the revound botty \n",
      "\n",
      "iter:6899/20000 loss:1.5728121626377105\n",
      "generated sequence: Wef\n",
      "     methopurder? You moor Bur that such who dustness, thought orcuured to\n",
      "     a feet a oned obr\n",
      "\n",
      "iter:6999/20000 loss:1.587190170288086\n",
      "generated sequence: Whing that to a forme Boota--peevinue to agare\n",
      "     eifesmingar\n",
      "     infushice\n",
      "     im.\"\n",
      "\n",
      "\n",
      "     \"I wi\n",
      "\n",
      "iter:7099/20000 loss:1.5716891479492188\n",
      "generated sequence: We?\"\n",
      "\n",
      "     I will in seared?'\n",
      "\n",
      "     Shat s. A formay; and blame!\"\n",
      "\n",
      "     I had lou. As I am anack and \n",
      "\n",
      "iter:7199/20000 loss:1.587963490486145\n",
      "generated sequence: Wels--ladyed was stoll and enazlizant pange make ingrond claved the dugatared in Insowed, is cemwisul\n",
      "\n",
      "iter:7299/20000 loss:1.570748689174652\n",
      "generated sequence: Willion womet interpopently.\"\n",
      "\n",
      "     \"The post bhat the\n",
      "     so if I am the allifull, Mr.\"\n",
      "\n",
      "     He wi\n",
      "\n",
      "iter:7399/20000 loss:1.5833737564086914\n",
      "generated sequence: Well, a ladgy eraw eveny my\n",
      "     waye of the seper\n",
      "     menting of a benoralf a doveventing thim his \n",
      "\n",
      "iter:7499/20000 loss:1.5469790410995483\n",
      "generated sequence: We came to Lasted, Mr. Brrankenc when I shay with or\n",
      "     before of the chougd, I had condid was find\n",
      "\n",
      "iter:7599/20000 loss:1.5647168815135957\n",
      "generated sequence: Willing of the\n",
      "     man in wend proced weach of exanger and fee sevice stonth of cogivated were a sid\n",
      "\n",
      "iter:7699/20000 loss:1.5536467146873474\n",
      "generated sequence: Whime.\"\n",
      "\n",
      "     \"Inde a toox, the rame, from the mame, the conssiratity with iistenfeser.\n",
      "\n",
      "     \"There \n",
      "\n",
      "iter:7799/20000 loss:1.6033505117893219\n",
      "generated sequence: Whait\n",
      "     thein baild in his quice and gear such fach Sole, the made hI have Was recape soin Holmes \n",
      "\n",
      "iter:7899/20000 loss:1.575615155696869\n",
      "generated sequence: We conceured if at wot\n",
      "e gnxacts in your serten.\"\n",
      "\n",
      "     \"She\n",
      "     abbust reasunizal trock through to \n",
      "\n",
      "iter:7999/20000 loss:1.5724565052986146\n",
      "generated sequence: Withwar cursed what them,\n",
      "\n",
      "     now a creet, and\n",
      "     and his beicge gut.\"\n",
      "\n",
      "     \"I dose had the drin\n",
      "\n",
      "iter:8099/20000 loss:1.5726637506484986\n",
      "generated sequence: Whist corndigain so-lourld nore the latter sine,\" is to athers of lies clooved thed to chandidgureman\n",
      "\n",
      "iter:8199/20000 loss:1.582860060930252\n",
      "generated sequence: Wels haited the said him.\"\n",
      "\n",
      "     \"'I has caully in his\n",
      "     comp and be heay's\n",
      "     rean--warms from \n",
      "\n",
      "iter:8299/20000 loss:1.5613283360004424\n",
      "generated sequence: Wipred and casenead. I ther. Tound happecusts hele, as and mpar leal. But his lah Back leavided his i\n",
      "\n",
      "iter:8399/20000 loss:1.550503340959549\n",
      "generated sequence: Weptirers which mornally. I fearly before was\n",
      "     criend, with\n",
      "     that not come Silf faiss\n",
      "     ab\n",
      "\n",
      "iter:8499/20000 loss:1.5591060483455659\n",
      "generated sequence: Whalke like of the dise cough in his calured to hir?\" he thill call more shasp 1050 bit be ome at ela\n",
      "\n",
      "iter:8599/20000 loss:1.5634549248218537\n",
      "generated sequence: Walked heg said my meant.\"\n",
      "\n",
      "     BUty seae, o'm stared has four of atmendy. \"You, and reason is bows \n",
      "\n",
      "iter:8699/20000 loss:1.5582899391651153\n",
      "generated sequence: Whime you. He\n",
      "     had had couroct of\n",
      "     has as the chie\n",
      "     from he cundal and\n",
      "     wamon you hun\n",
      "\n",
      "iter:8799/20000 loss:1.557409827709198\n",
      "generated sequence: Willer hianle;\n",
      "     bn the ocmintt and when\n",
      "     it\n",
      "     thrunden seemed a ferral of molan, the\n",
      "     \n",
      "\n",
      "iter:8899/20000 loss:1.5319989514350891\n",
      "generated sequence: Watson well, I've he cayes gobses, and suale in.\"\n",
      "\n",
      "     \"Hopent before gand be mosely earty, \"I stick\n",
      "\n",
      "iter:8999/20000 loss:1.5367017793655395\n",
      "generated sequence: Well. \"Awothery.\"\n",
      "\n",
      "     Tursecic and I'ch He makes, the Sfiriedy we will it was\n",
      "     foom thangers we\n",
      "\n",
      "iter:9099/20000 loss:1.5510511195659638\n",
      "generated sequence: Wet frimed the upent visttent, My, Sam offant Rathoutencivame to\n",
      "     of looked his facees, when we c\n",
      "\n",
      "iter:9199/20000 loss:1.5645447957515717\n",
      "generated sequence: Whole of held in my spresmoriated him talk off with the atsolf. I did not of with a gife. He was\n",
      "    \n",
      "\n",
      "iter:9299/20000 loss:1.5488361048698425\n",
      "generated sequence: We hald to\n",
      "     Alkind\n",
      "     of rurewuse-- He handly. I have to\n",
      "     the\n",
      "     mant! Whing\n",
      "     Cuthery\n",
      "\n",
      "iter:9399/20000 loss:1.5564747977256774\n",
      "generated sequence: Wass, to looked without pogeted awd was. Watso man is sixceabar twamce.\"\n",
      "\n",
      "     \"Simess\n",
      "     hunds at \n",
      "\n",
      "iter:9499/20000 loss:1.5512687122821809\n",
      "generated sequence: Whind\n",
      "     and Lold in somert.\"\n",
      "\n",
      "     \"Yeading takence, an eximbered there\n",
      "     indaysice Squeents fa\n",
      "\n",
      "iter:9599/20000 loss:1.5381553721427919\n",
      "generated sequence: Whimelly deach of Shim witanatien--\"What\n",
      "     by\n",
      "     bion it with read how, have they gaid it my edo\n",
      "\n",
      "iter:9699/20000 loss:1.5303699254989624\n",
      "generated sequence: What over thear in inut I have buting him most. Stive bating, the\n",
      "     whop a lafest as newe mornirgh\n",
      "\n",
      "iter:9799/20000 loss:1.5570524537563324\n",
      "generated sequence: Wet and thene at theur! Mr. Holmes old more powetslation the emplaiche powicue lookif urows! Parrows \n",
      "\n",
      "iter:9899/20000 loss:1.5576927721500398\n",
      "generated sequence: Wan but see more\n",
      "     town from\n",
      "     shell be found they! The man, see you their may falh ow in the m\n",
      "\n",
      "iter:9999/20000 loss:1.544841367006302\n",
      "generated sequence: Wischion\n",
      "     we all\n",
      "     light upon the wornd. Then had\n",
      "     siaphely his way like it out on the\n",
      "   \n",
      "\n",
      "iter:10099/20000 loss:1.5564708650112151\n",
      "generated sequence: Well-gain terrain not the coset to the same, may in it. She priver with EShoure. Exchient with with t\n",
      "\n",
      "iter:10199/20000 loss:1.5256062853336334\n",
      "generated sequence: Weld and rigive---has nore and buxned most plan bans. For,\"'s it.  I have by the last foult I before \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:10299/20000 loss:1.5253965151309967\n",
      "generated sequence: Wals as the some for Stants the worn. There would be ghe, brokand down om\n",
      "     hele. A chimplet and r\n",
      "\n",
      "iter:10399/20000 loss:1.5430208599567414\n",
      "generated sequence: Were, Mr. So it. Whe theconcless betwey From\n",
      "     non\n",
      "     appablers\n",
      "     a\n",
      "     deay of the hous! an\n",
      "\n",
      "iter:10499/20000 loss:1.5450627946853637\n",
      "generated sequence: Well?\"\n",
      "\n",
      "     \"Wy\n",
      "     wall. Laster, weight spotel banger adeligh had hapse, last nom.\n",
      "\n",
      "     \"Well to \n",
      "\n",
      "iter:10599/20000 loss:1.5184241700172425\n",
      "generated sequence: Which window hat aund, wallouss? In the walked the round like you any consectroors. \"My take, Witson'\n",
      "\n",
      "iter:10699/20000 loss:1.5304275965690612\n",
      "generated sequence: Whno to fath out in it wem, but it was aswortious--the readd high ax the PaPer a heme room. He had a \n",
      "\n",
      "iter:10799/20000 loss:1.5361183261871338\n",
      "generated sequence: Whte that\n",
      "     were, sittench which to phint of like any goin happen who hungon this worlows. He.\n",
      "   \n",
      "\n",
      "iter:10899/20000 loss:1.5396280491352081\n",
      "generated sequence: We\n",
      "     rememse it was quame of passongun on me mupe con't been if over over having monalfer thind th\n",
      "\n",
      "iter:10999/20000 loss:1.5197114908695222\n",
      "generated sequence: Wild almteting awave my poop in Chich wisherge at there of the reafted, for us gois station compos, a\n",
      "\n",
      "iter:11099/20000 loss:1.5363021910190582\n",
      "generated sequence: We to dasquires, the I hazp thear, preseute!\" I heave and the subitidercioned.\n",
      "\n",
      "     \"I have have was\n",
      "\n",
      "iter:11199/20000 loss:1.5497655701637267\n",
      "generated sequence: Whino ageine.\n",
      "     Honge box mad fith to stenivite murders, has grown honf, Holmes goor.\n",
      "\n",
      "     \"Noth-\n",
      "\n",
      "iter:11299/20000 loss:1.554692085981369\n",
      "generated sequence: With gave upon ut with soment. The roussmay,\n",
      "     with which deres?\"\n",
      "\n",
      " \n",
      "      the deach DiSting why h\n",
      "\n",
      "iter:11399/20000 loss:1.53003479719162\n",
      "generated sequence: We\n",
      "     seach to\n",
      "     no gave, on the whather whon, to be attine. With mornisssean in a\n",
      "     gen sobe\n",
      "\n",
      "iter:11499/20000 loss:1.5261293053627014\n",
      "generated sequence: Watson, and seenadstable gettueled the barofestions me\n",
      "     at had I convestiters which a mognesuld w\n",
      "\n",
      "iter:11599/20000 loss:1.5398788750171661\n",
      "generated sequence: With imvergorded concl they listol that did had conher\n",
      "     mack mosing and\n",
      "      when he\n",
      "     had s.\n",
      "\n",
      "iter:11699/20000 loss:1.525481412410736\n",
      "generated sequence: Will, as the cunsidic two\n",
      "     you over which alemble?'\n",
      "\n",
      "     Her stable the every quetting what\n",
      "    \n",
      "\n",
      "iter:11799/20000 loss:1.513577835559845\n",
      "generated sequence: We Bough, but these find.\n",
      "\n",
      "     \"Hersed you a Doverns. At the might his\n",
      "     convertinged buttrecal m\n",
      "\n",
      "iter:11899/20000 loss:1.5260182583332063\n",
      "generated sequence: Whatsudor. In gaid heme to sire whict at the possires exacturunted to see to Are. If counts of the br\n",
      "\n",
      "iter:11999/20000 loss:1.5286360502243042\n",
      "generated sequence: We drugh, would most is Driwn Hoved pitalar with punce you! But I was business, hould time hampled do\n",
      "\n",
      "iter:12099/20000 loss:1.49684596657753\n",
      "generated sequence: Well. I can explise for the more Poctogions for these at the\n",
      "     with preciarn\n",
      "     returng a forde \n",
      "\n",
      "iter:12199/20000 loss:1.5015635919570922\n",
      "generated sequence: Wellen of baiced dired conjustames, heand was a gangures her Sways, that his streamed him cardgatimen\n",
      "\n",
      "iter:12299/20000 loss:1.5139797067642211\n",
      "generated sequence: What will perpesow we could van propestays, and was art his my be ton was gonnsings you, and that sur\n",
      "\n",
      "iter:12399/20000 loss:1.5312227165699006\n",
      "generated sequence: When\n",
      "     when I gleme man\n",
      "     Back betly of increceed him examinable befooting the\n",
      "     long signed\n",
      "\n",
      "iter:12499/20000 loss:1.4953682076931\n",
      "generated sequence: Wetwar.\"\n",
      "\n",
      "     \"It's doow\n",
      "     have never\n",
      "     there impuses and that had\n",
      "     evidd\n",
      "     roome\n",
      "     \n",
      "\n",
      "iter:12599/20000 loss:1.4807968604564667\n",
      "generated sequence: Went ganing becrisited affear told alan, and his panced Watson\n",
      "     had littly inquailed not, with,\n",
      " \n",
      "\n",
      "iter:12699/20000 loss:1.5243577039241791\n",
      "generated sequence: Whot she ham gooppedear leftwer activer and a blood presemariesed three\n",
      "     the myist. I knot is the\n",
      "\n",
      "iter:12799/20000 loss:1.4956901335716248\n",
      "generated sequence: Wet an indeed friend-, and for cannst beyord by the unowning.\"\n",
      "\n",
      "     The disech\n",
      "     exairn and very \n",
      "\n",
      "iter:12899/20000 loss:1.5139012002944947\n",
      "generated sequence: What decurtical sincy of the\n",
      "     roomen it before the rest paction concemped than Wold severtion est\n",
      "\n",
      "iter:12999/20000 loss:1.509969700574875\n",
      "generated sequence: White\n",
      "     brosg\n",
      "     door of simman had asen could, as a very\n",
      "     man book there will you grower tr\n",
      "\n",
      "iter:13099/20000 loss:1.4973808479309083\n",
      "generated sequence: We certainful of the midey may of my fouffoghinesty there is to Extorotiry.\"\n",
      "\n",
      "     \"'\"Mnaw the fiffor\n",
      "\n",
      "iter:13199/20000 loss:1.5080089569091797\n",
      "generated sequence: Wits of\n",
      "\n",
      "     \"'I did comy his\n",
      "     they of 'ved,\" he main came from\n",
      "     beachee single fat bured fo\n",
      "\n",
      "iter:13299/20000 loss:1.5231554484367371\n",
      "generated sequence: Willy doculing, and in the nately\n",
      "     deach of mish of Barlible by it. The assidy heady savy left co\n",
      "\n",
      "iter:13399/20000 loss:1.5254061281681062\n",
      "generated sequence: Welshs your facle, ope of the fight sevel oarming\n",
      "    \n",
      "     locknes instent of life me to quare pans.\n",
      "\n",
      "iter:13499/20000 loss:1.5054571282863618\n",
      "generated sequence: Welle gatle fapens confirse. He,  an inday in\n",
      "     to up and sumprest Gles vaitle shoak gross two\n",
      "   \n",
      "\n",
      "iter:13599/20000 loss:1.5510839211940766\n",
      "generated sequence: Wis as sexperta. I wready in clummelly sail, afdet\n",
      "     then from sich all our cappeal to was us st.m\n",
      "\n",
      "iter:13699/20000 loss:1.517273565530777\n",
      "generated sequence: Waming of the remarked would dut Miss, it were me that ene mean\n",
      "     posime. The coneccounts yet aksi\n",
      "\n",
      "iter:13799/20000 loss:1.5237835013866425\n",
      "generated sequence: Wight are to seeves the\n",
      "     pussles\n",
      "     tha\n",
      "     delacessing the brought I reholly out by permise o\n",
      "\n",
      "iter:13899/20000 loss:1.5181804537773131\n",
      "generated sequence: We't any only\n",
      "     mysseancy reach ansted offfer by the vowinding and the raibed tell not\n",
      "     the ro\n",
      "\n",
      "iter:13999/20000 loss:1.5131546425819398\n",
      "generated sequence: Whosals, I\n",
      "     the wept by grich wrotenily. It was fever have ary, he pour, thankleson--no prevand m\n",
      "\n",
      "iter:14099/20000 loss:1.5172935700416565\n",
      "generated sequence: Whon it is thirp I. 'CHeppossion as varked to exprebarry out\n",
      "     or. Should be. \"Ah our poor the\n",
      "   \n",
      "\n",
      "iter:14199/20000 loss:1.5024475312232972\n",
      "generated sequence: Whitily down to have been for the work how so very all to\n",
      "     suct fricked with side\n",
      "     adot mind \n",
      "\n",
      "iter:14299/20000 loss:1.4802256941795349\n",
      "generated sequence: Wht be in the wothing about the wind plepe to conner with did I wiok we me, he was a corserted it in \n",
      "\n",
      "iter:14399/20000 loss:1.4837511098384857\n",
      "generated sequence: Whine should knows\n",
      "     rocestudyst\n",
      "     them,\" said had aly'pseamerced.\n",
      "\n",
      "     \"Well, there over's\n",
      "  \n",
      "\n",
      "iter:14499/20000 loss:1.489966870546341\n",
      "generated sequence: Whos\n",
      "     betorew. For me hat where The chase a room umpoor ow eave man's begorterling. Mr. Jumple\n",
      "  \n",
      "\n",
      "iter:14599/20000 loss:1.4901403605937957\n",
      "generated sequence: Wess which so the\n",
      "?     sour the lother bould.\n",
      "\n",
      "    \n",
      "     \"Tick Holmes was his\n",
      "     man horm,\n",
      "     pu\n",
      "\n",
      "iter:14699/20000 loss:1.4994392788410187\n",
      "generated sequence: Wibs--evenistly no bustare\n",
      "     should do fige to figh is a ciarilister. He could returly why was occ\n",
      "\n",
      "iter:14799/20000 loss:1.5296446311473846\n",
      "generated sequence: Wits\n",
      "     out of upreales lust examino, in an edgnen mogels on the greagen. \"Mr. Johe have ran. Then \n",
      "\n",
      "iter:14899/20000 loss:1.5147513198852538\n",
      "generated sequence: Wither the bubbry\n",
      "\n",
      "     \"You gressed the Engers his knight, with through you in eargh,oy survection.\n",
      "\n",
      "\n",
      "iter:14999/20000 loss:1.477725328207016\n",
      "generated sequence: Well, for he would nother hand, no manked whating we hasure was once arresionsage them anvite we coul\n",
      "\n",
      "iter:15099/20000 loss:1.4981188809871673\n",
      "generated sequence: Why firmes, \"You must thin long and minopo minds. Hum-Carded not this case one less got I\n",
      "     like h\n",
      "\n",
      "iter:15199/20000 loss:1.5392381846904755\n",
      "generated sequence: Wels in to Minvalon himself, and gualss apper of the une a\n",
      "     fellow-pos to interfugh? Pance, and c\n",
      "\n",
      "iter:15299/20000 loss:1.5205003893375397\n",
      "generated sequence: Widded\n",
      "     and fack to keef the overes my  stoolal smele to low, Great who into a clainst mansely sh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:15399/20000 loss:1.4817226314544678\n",
      "generated sequence: We stypottang in hisheding in me instrects.\n",
      "     \"That, and he dimssiers, intstain down the drouble g\n",
      "\n",
      "iter:15499/20000 loss:1.4874404239654542\n",
      "generated sequence: Was spon\n",
      "     you see is ieman with a the morny crese what\n",
      "     I was from just I groon the goon from\n",
      "\n",
      "iter:15599/20000 loss:1.4999211418628693\n",
      "generated sequence: Wels.\"\n",
      "\n",
      "     \"Sir, the aways am such they last might business to puphie in, has cassable in eyes in t\n",
      "\n",
      "iter:15699/20000 loss:1.5083181428909302\n",
      "generated sequence: We this appectled. Ahsure to shoous, I see fol--hearhturlly\n",
      "     a Solenn freized?\"\n",
      "\n",
      "     \"Anytlis li\n",
      "\n",
      "iter:15799/20000 loss:1.4849495637416839\n",
      "generated sequence: Weaved. Aliay of evenion, we sholmate howells upon the queroush. Mervil thinkened that this find me, \n",
      "\n",
      "iter:15899/20000 loss:1.5344503688812257\n",
      "generated sequence: Will us wh her thir Wandible doal you a she\n",
      "     do at the nemeror unexman, liect,\" said she\n",
      "     mor\n",
      "\n",
      "iter:15999/20000 loss:1.4744543480873107\n",
      "generated sequence: What left with!\" I turned over it, and have your into it must seen we ceal see than me sungy acquent \n",
      "\n",
      "iter:16099/20000 loss:1.4910141825675964\n",
      "generated sequence: Wioned annwin of beven and tencemes to an inat back.'\n",
      "\n",
      "     \"'No, It winlon think emes to lefcisions.\n",
      "\n",
      "iter:16199/20000 loss:1.479359699487686\n",
      "generated sequence: Well besk worded, now comporder to exquegered,\n",
      "     secietuent in a hifn had been forting  reards was\n",
      "\n",
      "iter:16299/20000 loss:1.4682569694519043\n",
      "generated sequence: Wethsin thes, for would was a cry. Lotide.\n",
      "\n",
      "     \"The horration!\n",
      "     Excoptoes.\n",
      "\n",
      "     \"Have formed e\n",
      "\n",
      "iter:16399/20000 loss:1.4982081615924836\n",
      "generated sequence: Wet. A singlef myind hart my ed some stoudst infersidarg\n",
      "     Lown.\"\n",
      "\n",
      "     \"Actay, down his poinch. I\n",
      "\n",
      "iter:16499/20000 loss:1.4921831059455872\n",
      "generated sequence: Wibsor, thanker, and among way a gree sigain shill feath, in ittes did Here you very poines the fases\n",
      "\n",
      "iter:16599/20000 loss:1.4958463680744172\n",
      "generated sequence: What mess thin?'\n",
      "\n",
      "     The shat it help undientloke ob away upsionci for as therinadse of the saley a\n",
      "\n",
      "iter:16699/20000 loss:1.5052083575725554\n",
      "generated sequence: What iauch in a gay stroke you, call calter if you have the hall, dow what saidstur warlos one only f\n",
      "\n",
      "iter:16799/20000 loss:1.4881809735298157\n",
      "generated sequence: Whole, I am my necess. Finityed in his last that I geven and as me a couminacate I may befining dotot\n",
      "\n",
      "iter:16899/20000 loss:1.4869703590869903\n",
      "generated sequence: Whome?\" she candly for none? I on the Yond face when an appouses, there was no mank one. There appoin\n",
      "\n",
      "iter:16999/20000 loss:1.5002747237682343\n",
      "generated sequence: Wetters were, belance after at that that lik my beat renucious it\n",
      "     mad\n",
      "     acting. But they\n",
      "    \n",
      "\n",
      "iter:17099/20000 loss:1.5009450447559356\n",
      "generated sequence: Witmey his\n",
      "     Porthionots ordy?\"\n",
      "\n",
      "     \"Rouble asaid, follown and feattes litelled as mositicasy mo\n",
      "\n",
      "iter:17199/20000 loss:1.4805714976787567\n",
      "generated sequence: With a woman He\n",
      "     brith! I smacten with you were owners. I'ver calfed\n",
      "     and comma thought how c\n",
      "\n",
      "iter:17299/20000 loss:1.4598366367816924\n",
      "generated sequence: Wels it was you have morning of that is time through the brain for-I she came.\"\n",
      "\n",
      "     \"Not he was she\n",
      "\n",
      "iter:17399/20000 loss:1.4676077818870545\n",
      "generated sequence: Wet merday of his fore devillan.\n",
      "\n",
      "     \"Well, more gight.\"\n",
      "\n",
      "      And to glas\n",
      "     sirved his myself \n",
      "\n",
      "iter:17499/20000 loss:1.4903059530258178\n",
      "generated sequence: Whth lide a dried a now,\n",
      "     the pertles. It was seemed. If Morsing that I sead he was moot. 'Yet no\n",
      "\n",
      "iter:17599/20000 loss:1.4907229232788086\n",
      "generated sequence: Wh,\n",
      "     most to Scould be a younged it ond you't interisser watans who sour. \"I have some chouply oe\n",
      "\n",
      "iter:17699/20000 loss:1.4692118072509766\n",
      "generated sequence: Whitieds forvectivalem, Ho stand at to should do you hour excisconer was he would?\"\n",
      "\n",
      "          THE AD\n",
      "\n",
      "iter:17799/20000 loss:1.4812965631484984\n",
      "generated sequence: Wister, fog, and in the corting, Mr.  shappessional nowd to the finite. There three to them listre ch\n",
      "\n",
      "iter:17899/20000 loss:1.4753727209568024\n",
      "generated sequence: Wht ob. \n",
      "\n",
      "     \"Wh his\n",
      "     other all the mudder, he hauther was all of\n",
      "     he! I\n",
      "     veey sye befo\n",
      "\n",
      "iter:17999/20000 loss:1.4923538863658905\n",
      "generated sequence: Well,\" said he I'm     he would be some out like to doff of the Siglon Holmes?\" Any\n",
      "     can oods of \n",
      "\n",
      "iter:18099/20000 loss:1.457369465827942\n",
      "generated sequence: Wels ichat wathe glased. They so?\"\n",
      "\n",
      "     Do the epphish, If anaidityon twiton-lady toot dayth cause r\n",
      "\n",
      "iter:18199/20000 loss:1.4830670845508576\n",
      "generated sequence: Well. I was protical that cappeef\n",
      "     comes oct it tear.\n",
      "\n",
      "     \"\n",
      "\n",
      "     \"The eable as worned in my re\n",
      "\n",
      "iter:18299/20000 loss:1.4785219025611878\n",
      "generated sequence: Wet and the miin such mented in a from dolother in the cretier\n",
      "     Godge. I am, the Marest\n",
      "     were\n",
      "\n",
      "iter:18399/20000 loss:1.4794441866874695\n",
      "generated sequence: Which mifficudnted with a dispacy ilans. In the oft can onligreves.\n",
      "\n",
      "     We currattled. \"You dur the\n",
      "\n",
      "iter:18499/20000 loss:1.4970025289058686\n",
      "generated sequence: When far\n",
      "     happletcrest toll yet after of spoke for when it, hus when I harobyt\n",
      "     roobs realm, \n",
      "\n",
      "iter:18599/20000 loss:1.4893463742733002\n",
      "generated sequence: Wilt\n",
      "     Mustice to hees up it my letterstated that impoldrever my pleaking still Partiest that thea\n",
      "\n",
      "iter:18699/20000 loss:1.482258049249649\n",
      "generated sequence: Wh you---rowat shock,\n",
      "     for the elescove. In age anioen dark donunes. Pirtly. The yourt at the bed\n",
      "\n",
      "iter:18799/20000 loss:1.4941473197937012\n",
      "generated sequence: What of flancy down. It was he. \"You arrow Colinor into me with lost to the polte\n",
      "     a fallE who, I\n",
      "\n",
      "iter:18899/20000 loss:1.469649587869644\n",
      "generated sequence: Witt in the cold it. The haid acquirled his caisude which he reason, and telloch\n",
      "     fellow reswed a\n",
      "\n",
      "iter:18999/20000 loss:1.4752541089057922\n",
      "generated sequence: What vaully\n",
      "     knothough in it. I troutly.  Whis sur, and that in a ligried and impolicMuld.\n",
      "\n",
      "     \n",
      "\n",
      "iter:19099/20000 loss:1.4861563408374787\n",
      "generated sequence: What alreasher been glinte canly lical sirwey was a Rod.\"\n",
      "\n",
      "     \"Was trireher,\n",
      "     the\n",
      "     brown of\n",
      "\n",
      "iter:19199/20000 loss:1.508544921875\n",
      "generated sequence: Whito! I could be we put some comptink awarwentwness, and that he put? I should be no open was not ch\n",
      "\n",
      "iter:19299/20000 loss:1.4587914848327637\n",
      "generated sequence: Wets were suguten man,\" soice to the mance we was rest.\n",
      "\n",
      "     \"We werness, the sibtain time flome bar\n",
      "\n",
      "iter:19399/20000 loss:1.4623681342601775\n",
      "generated sequence: Whito the game my askervard brown with poctir?\"\n",
      "\n",
      "     \"Have you make stere over.\"\n",
      "\n",
      "     \"In throad to\n",
      "\n",
      "iter:19499/20000 loss:1.454768100976944\n",
      "generated sequence: Why think it before at courses of their repair\n",
      "     Barrystant.\"\n",
      "\n",
      "     Whok is leave for the case spe\n",
      "\n",
      "iter:19599/20000 loss:1.4695452535152436\n",
      "generated sequence: Wastred,, and led rookence, Watson, Mr. Holmess to the record who had our cignerts, no\n",
      "     end a mat\n",
      "\n",
      "iter:19699/20000 loss:1.4686703503131866\n",
      "generated sequence: Whine upportsely--nature when she canned, Lringer, afthied, the papers and complet and a\n",
      "     new dat\n",
      "\n",
      "iter:19799/20000 loss:1.4983197247982025\n",
      "generated sequence: Whon\n",
      "     yet his almpledsed him by our cold-avower himself in dark, in some newgrment anseconding th\n",
      "\n",
      "iter:19899/20000 loss:1.450895789861679\n",
      "generated sequence: Wep occurred. It was givled,\n",
      "     to be presone of hising sinion.\n",
      "\n",
      "     \"I knee window-of would\n",
      "     \n",
      "\n",
      "iter:19999/20000 loss:1.4635676050186157\n",
      "generated sequence: Whan examined, eeppoes, Withed roack of\n",
      "     the poison me, Mr. Holmes. Tear, and this\n",
      "     concar, t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "# NOTE: You may reduce the number of training iterations if the training takes long.\n",
    "iters       = 20000  # Number of training iterations.\n",
    "print_iters = 100    # Number of iterations for each log printing.\n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adam(net.parameters(), lr=0.002)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    loss      = train_step(net, opt, input, target)   # Calculate the loss.\n",
    "    loss_sum += loss.item()                             # Accumulate the loss.\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(eval_step(net)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why sonerd and agearse ahar linich hour, but we here\n",
      "     we had no liked.\"\n",
      "\n",
      "     \"Yes, with his bringat.\n",
      "\n",
      "     \"I have his dolshats. You were no would oeper. Then it my of heog calling of a can on in\n",
      "     the stage as no doam, dhid, sofing to his kecentted, and given the Treepland, back had seen, and I get an his\n",
      "     an in port, which a caken. This fect\n",
      "     chet, no\n",
      "     cleach down the nood-good at\n",
      "     above the edwed,\" inthing of his slep open as to\n",
      "     aguating sum! He was prusure.\n",
      "\n",
      "     \"Anloweraal worked on if he eine listanic, and they cart of mone, she lilfsy then? It oerers quier d\n"
     ]
    }
   ],
   "source": [
    "print(eval_step(net, predicted_len=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
